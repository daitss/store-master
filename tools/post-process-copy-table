#!/usr/bin/env ruby

# It requires data be gathered from the silos service database:
#
# echo "select name, size, latest_sha1, latest_md5, case when latest_md5=initial_md5 then 'ok' else 'fail' end, initial_timestamp from packages where extant order by name" | db production_silo | grep -v latest_sha1 | grep -v ^--- | sed -e 's/|//g' -e 's/^ //'
#
# save the output to darchive.text, tarchive.text - it looks like this:
#
# E20051012_AAAAAA   1016350720  0d37bd6cebd25d5601abe61ede71e1fcf31b35b7  85d8585997f6c40b0ab559072c78137d  ok    2008-05-23 10:32:41-04
# E20051012_AAAAAB    958720000  8533c8362453b75afc8c911e2b9b230445fc380c  bef2badc1234d429b34cec1879e2f0d0  ok    2008-05-23 10:35:15-04
# E20051012_AAAAAC     48906240  04d725a57f58e2459db385fb520c8d30fbe68b16  dfbdd28ff3c19488ec6115966f9f174a  ok    2008-05-23 10:44:47-04

$LOAD_PATH.unshift '/opt/web-services/sites/storemaster/current/lib'

require 'time'
require 'datyl/streams'
require 'datyl/logger'
require 'store-master/model'
require 'daitss/model'

module Streams

  Struct.new('PoolFixityRecord', :size, :sha1, :md5, :status, :timestamp)

  class PoolDataStream < DataFileStream

    def read
      rec = @io.gets.strip.split(/\s+/, 6)
      # e.g.
      # [ "E20051012_AAAAAA", "1016350720", "0d37bd6cebd25d5601abe61ede71e1fcf31b35b7", "85d8585997f6c40b0ab559072c78137d", "ok",   "2008-05-23 10:32:41-04" ]
      #    ieid                size          sha1                                        md5                                 status  timestamp
      #    0                   1             2                                           3                                   4       5
      return rec[0], Struct::PoolFixityRecord.new(rec[1].to_i, rec[2], rec[3], rec[4], Time.parse(rec[5]))
    end

  end
end  # of module Streams


def setup
  Logger.setup('CopyTableUpdate', 'storemaster.fda.fcla.edu')
  Logger.stderr 

  Daitss.setup_db('/opt/fda/etc/db.yml', 'ps_daitss_2')
end

include Daitss
include Streams

setup()

# PoolDataStream looks as so:
#
#   E20110129_CYXBHO,  #<struct Struct::PoolFixityRecord 
#                               size=1016350720,
#                               sha1="0d37bd6cebd25d5601abe61ede71e1fcf31b35b7",
#                               md5="85d8585997f6c40b0ab559072c78137d",
#                               status="ok",
#                               timestamp=Fri May 23 10:32:41 -0400 2008>
#
# We get the data from the silo database, see comments above

cmp = ComparisonStream.new(PoolDataStream.new(File.open('darchive.text')),
                           PoolDataStream.new(File.open('tarchive.text')))

cmp.each do |ieid, v1, v2|

  if v1.nil?
    Logger.warn "#{ieid} missing from darchive: tarchive has " + v2.inspect
    if v2.status != 'ok'
      Logger.err "Only copy for #{ieid} has failed status, skipping"
      next
    end

    md5  = v2.md5
    sha1 = v2.sha1
    size = v2.size
    time = v2.timestamp

  elsif v2.nil?
    Logger.warn "#{ieid} missing from tarchive: darchive has " + v1.inspect

    if v1.status != 'ok'
      Logger.err "Only copy for #{ieid} has failed status, skipping"
      next
    end

    md5  = v1.md5
    sha1 = v1.sha1
    size = v1.size
    time = v1.timestamp
    
  else # we have both records...

    if v1.status != 'ok' and v2.status != 'ok'
      Logger.err "#{ieid} has no good fixity checks, skipping"
      next

    elsif v1.status != 'ok'
      Logger.warn "#{ieid} from darchive is bad, using tarchive's"

      md5  = v2.md5
      sha1 = v2.sha1
      size = v2.size
      time = [ v1.timestamp, v2.timestamp ].max

    elsif v2.status != 'ok'
      Logger.warn "#{ieid} from tarchive is bad, using darchive's"

      md5  = v1.md5
      sha1 = v1.sha1
      size = v1.size
      time = [ v1.timestamp, v2.timestamp ].max

    else # now we have two fixity checks marked as ok; further sanity check the two records:

      if v1.md5 != v2.md5 or v1.sha1 != v2.sha1 or v1.size != v2.size
        Logger.err "#{ieid} mismatched fixities that were reported ok - #{v1.inspect}  vs.  #{v2.inspect}"
        next
      end

      md5  = v1.md5
      sha1 = v1.sha1
      size = v1.size
      time = [ v1.timestamp, v2.timestamp ].max

    end

    url = "http://storemaster.fda.fcla.edu:70/packages/#{ieid}"

    record = Copy.first(:url => url, :md5 => md5)

    if not record
      Logger.err "#{ieid} has no copy record for #{url} #{md5}"
      next
    end
    
    record.sha1 = sha1
    record.size = size
    record.timestamp = time

    if not record.save
       Logger.err "#{ieid} - can't save copy record: "  + record.errors.full_messages.join('; ')
    else
      Logger.info "#{ieid} updated with #{sha1}, #{time}, #{size}"
    end

  end
end  # of each
