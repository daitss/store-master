#!/usr/bin/env ruby

# TODO:  print out configuration information in log

$LOAD_PATH.unshift File.join(File.dirname(__FILE__), '../lib/')

require 'datyl/config'
require 'datyl/logger'
require 'datyl/reporter'
require 'datyl/streams'
require 'optparse'
require 'store-master'


def get_config
  raise StoreMaster::ConfigurationError, "No DAITSS_CONFIG environment variable has been set, so there's no configuration file to read"             unless ENV['DAITSS_CONFIG']
  raise StoreMaster::ConfigurationError, "The DAITSS_CONFIG environment variable points to a non-existant file, (#{ENV['DAITSS_CONFIG']})"          unless File.exists? ENV['DAITSS_CONFIG']
  raise StoreMaster::ConfigurationError, "The DAITSS_CONFIG environment variable points to a directory instead of a file (#{ENV['DAITSS_CONFIG']})"     if File.directory? ENV['DAITSS_CONFIG']
  raise StoreMaster::ConfigurationError, "The DAITSS_CONFIG environment variable points to an unreadable file (#{ENV['DAITSS_CONFIG']})"            unless File.readable? ENV['DAITSS_CONFIG']
  
  config = Datyl::Config.new(ENV['DAITSS_CONFIG'], 'defaults', 'database', 'collect-fixities')


  [ 'daitss_db', 'storemaster_db', 'server_address', 'fixity_expired_days', 'fixity_stale_days', 'required_pools'].each do |option|
    raise StoreMaster::ConfigurationError, "The daitss configuration file #{ENV['DAITSS_CONFIG']} did not set the '#{option}' option" unless config[option]
  end

  return config

rescue => e
  STDERR.puts e.message
  exit 1
end


def setup config
  $0 = 'test-cf'

  Datyl::Logger.setup('TestCF', config.server_address.gsub(/:.*/, ''))

  Datyl::Logger.facility = config.log_syslog_facility  if config.log_syslog_facility
  Datyl::Logger.filename = config.log_filename         if config.log_filename
  Datyl::Logger.stderr     unless (config.log_filename or config.log_syslog_facility)

  config.keys.sort.each do |option|

    next unless [ 'fixity_expired_days', 'fixity_stale_days', 'log_database_queries', 'pid_directory',
                  'required_pools', 'server_address', 'daitss_db', 'storemaster_db' ].include? option

    Datyl::Logger.info "Configuration: #{option} =>  #{StoreUtils.safen_connection_string(config[option].to_s)}"
  end


  if config.pid_directory
    pid_path = StoreUtils.pid_file(config.pid_directory)

    if File.exists? pid_path
      raise "PID file #{pid_path} exists. This indicates another copy of this program is running or has previously crashed; exiting"
    end

    File.open(pid_path, 'w') { |file|  file.puts $$ }
  end

  DataMapper::Logger.new(Datyl::Logger.new(:info, 'DataMapper:'), :debug) if config.log_database_queries

  Datyl::Reporter.max_lines_to_write = 2000   # each report will have at most these lines, though everything will go to syslog
  StoreMasterModel::Package.server_location = "http://#{config.server_address}"  # TODO: crummy backdoor way, rethink this...

  # StoreMasterModel.setup_db(config.storemaster_db)
  # Daitss.setup_db(config.daitss_db)

  StoreMaster.setup_databases(config.storemaster_db, config.daitss_db)


rescue => e
  Datyl::Logger.err e.message
  STDERR.puts e.message
  exit 1
end


def teardown config, streams
  if config.pid_directory
    pid_path = StoreUtils.pid_file(config.pid_directory)
    File.delete pid_path if File.exists? pid_path and File.writable? pid_path
  end
end


# MAIN:

config = get_config()
setup(config)

begin
  start_time = DateTime.now

  Datyl::Reporter.note "CollectFixities started at #{Time.now}"

  # Get our data streams to reconcile, some from web services
  # (silo-pool), some from the DAITSS database.  The order we use to
  # construct them next is important because it can take half a minute
  # to get the list of active packages from DAITSS' db; DAITSS might
  # be deleting or adding files at that time.  The problem of DAITSS
  # adding files to storage is solved by using the stored-before time,
  # but if DAITSS is deleting something while we wait for
  # daitss_fixity_stream to build, then it might show up as an orphan,
  # had we assembled the list of pool_fixity_streams first.
  

  daitss_fixity_stream = Streams::DaitssPackageStream.new(:before => start_time)
  pool_fixity_streams  = StoreMasterModel::Pool.list_active.map { |pool| Streams::PoolFixityStream.new(pool, { 'stored-before' => start_time } ) }

  reports = []

  reports.concat Analyzer::PoolVsDaitssAnalyzer.new(pool_fixity_streams, daitss_fixity_stream, config.required_pools, config.fixity_expired_days, config.fixity_stale_days, start_time).run.reports

  # TODO: these turn out to be somewhat redundant, maybe put into their own script?
  #
  # store_master_stream  = Streams::StoreMasterPackageStream.new
  #
  # reports.concat Analyzer::IntraPoolAnalyzer.new(pool_fixity_streams, config.expiration_days).run.reports
  # reports.concat Analyzer::InterPoolAnalyzer.new(pool_fixity_streams, config.required_copies).run.reports
  # reports.concat Analyzer::StoreMasterAnalyzer.new(store_master_stream, config.required_copies).run.reports
  # reports.concat Analyzer::StoreMasterVsPoolAnalyzer.new(store_master_stream, pool_fixity_streams).run.reports

  reports.each { |report| report.write if report.interesting? }

  Datyl::Reporter.note "CollectFixities finished at #{Time.now}"

rescue => e
  lede = "#{e.class}: #{e.message} - backtrace follows:"

  STDERR.puts lede
  e.backtrace.each { |line| STDERR.puts line }

  Datyl::Logger.err  lede
  e.backtrace.each { |line| Datyl::Logger.err line }
else
  teardown(config, pool_fixity_streams)
end
